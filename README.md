# `llama_cpp_jll.jl` (v0.0.12+1)

This is an autogenerated package constructed using [`BinaryBuilder.jl`](https://github.com/JuliaPackaging/BinaryBuilder.jl).

## Documentation

For more details about JLL packages and how to use them, see `BinaryBuilder.jl` [documentation](https://docs.binarybuilder.org/stable/jll/).

## Sources

The tarballs for `llama_cpp_jll.jl` have been built from these sources:

* git repository: https://github.com/ggerganov/llama.cpp.git (revision: `41c674161fb2459bdf7806d1eebead15bc5d046e`)

## Platforms

`llama_cpp_jll.jl` is available for the following platforms:

* `macOS aarch64` (`aarch64-apple-darwin`)

## Products

The code bindings within this package are autogenerated from the following `Products`:

* `LibraryProduct`: `libembdinput`
* `LibraryProduct`: `libggml`
* `LibraryProduct`: `libllama`
* `ExecutableProduct`: `baby_llama`
* `ExecutableProduct`: `benchmark`
* `ExecutableProduct`: `embd_input_test`
* `ExecutableProduct`: `embedding`
* `ExecutableProduct`: `main`
* `ExecutableProduct`: `perplexity`
* `ExecutableProduct`: `quantize`
* `ExecutableProduct`: `quantize_stats`
* `ExecutableProduct`: `save_load_state`
* `ExecutableProduct`: `server`
* `ExecutableProduct`: `simple`
* `ExecutableProduct`: `train_text_from_scratch`
